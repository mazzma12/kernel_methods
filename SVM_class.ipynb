{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg\n",
    "\n",
    "# cvxopt QP solver\n",
    "import cvxopt\n",
    "from cvxopt import solvers, matrix\n",
    "solvers.options['show_progress'] = False # Verbose quite\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "\n",
    "class SVM:\n",
    "    \n",
    "    def __init__(self, C=1, kernel='rbf', gamma=0.1, mode='OVO', loss='hinge_loss', c=0, degree=2):\n",
    "        self.C = C\n",
    "        self.kernel = kernel # kernel_function 'rbf', 'linear'\n",
    "        self.gamma = gamma # Kernel coefficient gamma for 'rbf'\n",
    "        self.loss = loss\n",
    "        self.mode = mode\n",
    "        self.c = c # Intercept of the polynomial kernel\n",
    "        self.degree = degree # Degree of the polynomial kernel\n",
    "        self.alphas_ = [] # coefficients of the estimators\n",
    "\n",
    "    def fit(self, X, y, ):\n",
    "        \n",
    "        self.X_train_ = X\n",
    "        self.n_samples_ = y.shape[0] # n_samples\n",
    "        self.classes_, self.repartition_ = np.unique(y, return_counts=True)\n",
    "        self.classes_ = self.classes_.astype(int)\n",
    "        self.n_classes_ = self.classes_.shape[0]\n",
    "        self.repartition_ = self.repartition_ / self.n_classes_\n",
    "        self.K_ = self.fit_kernel()\n",
    "        \n",
    "        \n",
    "        if self.mode == 'OVA':\n",
    "            \n",
    "            for class_ in self.classes_:\n",
    "                y_copy = y.copy()\n",
    "                y_copy[y_copy != class_] = -1\n",
    "                y_copy[y_copy == class_] = 1\n",
    "                self.fit_dual(y_copy)\n",
    "                \n",
    "                # Solving the QP\n",
    "                sol = solvers.qp(matrix(self.K_), matrix(self.p_), matrix(self.G_), matrix(self.h_))\n",
    "                # Saving the solution\n",
    "                self.alphas_.append(np.array(sol['x']).reshape(-1,))\n",
    "    \n",
    "        elif self.mode == 'OVO':\n",
    "            \n",
    "            masks_samples = [] # empty boolean list, True if the sample is in the current OVO comparison\n",
    "    \n",
    "            for class_plus in range(self.n_classes_):\n",
    "                for class_minus in range(class_plus+1, 10):\n",
    "                    y_copy = y.copy()\n",
    "                    \n",
    "                    # Mask select the samples which match the classes considered in the current OVO comparison\n",
    "                    mask = (y_copy == class_plus) | (y_copy == class_minus)\n",
    "                    masks_samples.append(mask) # saving the mask\n",
    "                    y_copy = y_copy[mask]\n",
    "                    y_copy[y_copy == class_minus] = -1\n",
    "                    y_copy[y_copy == class_plus] = 1\n",
    "                    \n",
    "                    # Updating the size of the subproblem for the dual computation\n",
    "                    # Important otherwise it would be built for n_samples = all the sample\n",
    "                    self.n_samples_ = y_copy.shape[0]\n",
    "\n",
    "                    this_K = self.K_[mask, :]\n",
    "                    this_K = this_K[:, mask]\n",
    "                    self.fit_dual(y_copy)\n",
    "                    # Solvign the QP\n",
    "                    sol = solvers.qp(matrix(this_K), matrix(self.p_), matrix(self.G_), matrix(self.h_))\n",
    "                    # Saving the solution in list attibute alphas_\n",
    "                    self.alphas_.append(np.array(sol['x']).reshape(-1,))\n",
    "                    \n",
    "            # Don't forget to update the n_samples attribute again\n",
    "            self.n_samples_ = y.shape[0] \n",
    "            # Saving the masks as attributes\n",
    "            self.masks_samples_ = np.array(masks_samples)\n",
    "            \n",
    "        else:\n",
    "            raise Exception('mode should be OVA or OVO')\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        self.K_test_ = self.fit_kernel_test(X_test)\n",
    "        self.n_test_ = X_test.shape[0] # size of the test sample\n",
    "        n = self.n_test_\n",
    "        \n",
    "        if self.mode == 'OVA':\n",
    "            classes_res = np.empty((self.classes_.shape[0], n))\n",
    "\n",
    "            for class_ in self.classes_:\n",
    "                alpha = self.alphas_[class_]\n",
    "                classes_res[class_] = np.dot(self.K_test_, alpha)\n",
    "            y_pred = classes_res.argmax(axis=0)\n",
    "            return y_pred\n",
    "        \n",
    "        elif self.mode == 'OVO':\n",
    "            \n",
    "            # calling OVO_estimators_masks() to built masks_estimators\n",
    "            # Used in masks_estimators*K_test later\n",
    "            # rmk : OVO_estimators_masks() is always the same, but cheap to compute\n",
    "            self.masks_estimators_ = OVO_estimators_masks()            \n",
    "            \n",
    "            estimators_preds = [] # list of length n_estimators which contains the predictions\n",
    "            # n_estimators = 45 in OVO : n_classes_(n_classes+1)/2\n",
    "            \n",
    "            for idx, mask in enumerate(self.masks_samples_):\n",
    "                alpha = self.alphas_[idx]\n",
    "                estimators_preds.append(np.dot(self.K_test_[:, mask], alpha))\n",
    "            \n",
    "            # Converting the result and taking the sign for prediction\n",
    "            estimators_preds = np.sign(np.array(estimators_preds))\n",
    "            \n",
    "            # Choosing which class is predicted using the mask_matrix built with OVO_idx_class()\n",
    "            classes_preds = [] # list of length n_classes_, contain the predictions for each class\n",
    "            for mask in self.masks_estimators_:\n",
    "                class_pred = estimators_preds.copy()\n",
    "                class_pred = class_pred*mask.reshape(-1,1)\n",
    "                class_pred[class_pred < 0] = 0\n",
    "                class_pred = class_pred.sum(0)\n",
    "                classes_preds.append(class_pred)\n",
    "            \n",
    "            classes_preds = np.array(classes_preds)\n",
    "            \n",
    "            # Argmax give the index of the row with the highest score\n",
    "            # rows are ordered so the index corresponds to the class\n",
    "            y_pred = classes_preds.argmax(0)\n",
    "            \n",
    "            return y_pred\n",
    "\n",
    "    def fit_kernel(self):\n",
    "        \n",
    "        X = self.X_train_\n",
    "        \n",
    "        if self.kernel == 'rbf':\n",
    "            pairwise_dists = squareform(pdist(X, 'euclidean'))\n",
    "            K = scipy.exp(-self.gamma*pairwise_dists ** 2)\n",
    "        \n",
    "        elif self.kernel == 'linear':\n",
    "            # In fact it's not a kernel\n",
    "            K = np.dot(X, X.transpose())\n",
    "        \n",
    "        elif self.kernel == 'polynomial':\n",
    "            K = (self.c + np.dot(X, X.transpose())) ** self.degree\n",
    "                       \n",
    "        else:\n",
    "            raise Exception('the kernel must either be rbf or linear')\n",
    "                       \n",
    "        return K\n",
    "                       \n",
    "    def fit_kernel_test(self, X_test):\n",
    "        # Compute the kernel gram matrix for the TEST set\n",
    "            \n",
    "        if self.kernel == 'rbf':\n",
    "            pairwise_dists = cdist(X_test, self.X_train_)\n",
    "            K = scipy.exp(-self.gamma*pairwise_dists ** 2)\n",
    "        \n",
    "        elif self.kernel == 'linear':\n",
    "            K = np.dot(X_test, self.X_train_.transpose() + self.c)\n",
    "                       \n",
    "        elif self.kernel == 'polynomial':\n",
    "            K = (self.c + np.dot(X_test, self.X_train_.transpose())) ** self.degree \n",
    "                       \n",
    "        else:\n",
    "            raise Exception('the kernel must either be rbf or linear')\n",
    "        \n",
    "        return K\n",
    "    \n",
    "    def fit_dual(self, y):\n",
    "        \n",
    "        if self.loss == 'hinge_loss':\n",
    "            n = self.n_samples_\n",
    "            diag_y = np.diag(y)\n",
    "            self.p_ = (-y)\n",
    "            self.Q_ = self.K_ # Quadratic matrix\n",
    "            self.G_ = np.r_[diag_y, -diag_y] # Constraint matrix of size(2*n, n)\n",
    "            self.h_ = np.r_[self.C*np.ones(n), np.zeros(n)]\n",
    "                       \n",
    "        elif self.loss == 'squared_hinge_loss':\n",
    "            \"\"\"\n",
    "            in progress\"\"\"\n",
    "            \n",
    "        else:\n",
    "            raise Exception('loss should be hinge loss or squared_hinge_loss')\n",
    "        \n",
    "        return self\n",
    "                       \n",
    "    def describe(self):\n",
    "        # Describe the train set\n",
    "        print(\" The Data contain \", self.n_classes_, \" classes, and the repartion is :  \", self.repartition_)\n",
    "\n",
    "def OVO_estimators_masks():\n",
    "    # DIFFICULT\n",
    "    # Build a matrix with 1 and 0 for the OVO prediction\n",
    "    masks = []\n",
    "    for n in range(10):    \n",
    "        mask = []\n",
    "        for k in range(10):\n",
    "            for j in range(k+1, 10):\n",
    "                if (k == n) | (j==n):\n",
    "                    if j==n:\n",
    "                        mask.append(-1)\n",
    "                    else:\n",
    "                        mask.append(1)\n",
    "                else:\n",
    "                    mask.append(0)\n",
    "        mask = np.array(mask)\n",
    "        masks.append(mask)\n",
    "    masks = np.array(masks)\n",
    "    return masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.69 s, sys: 88 ms, total: 4.78 s\n",
      "Wall time: 4.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_X_train = pd.read_csv('Xtr.csv', header=None, usecols=np.arange(3072))\n",
    "df_X_test = pd.read_csv('Xte.csv', header=None, usecols=np.arange(3072))\n",
    "df_y_train = pd.read_csv('Ytr.csv')\n",
    "\n",
    "\n",
    "X_train = np.array(df_X_train, dtype=float)\n",
    "X_test = np.array(df_X_test, dtype=float)\n",
    "y_train = np.array(df_y_train['Prediction'], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:11: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:12: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.19\n",
      "3\n",
      "0.19\n",
      "4\n",
      "0.19\n"
     ]
    }
   ],
   "source": [
    "### TEST PART ###\n",
    "\n",
    "# Amount of data used for train and for test\n",
    "n_train = 1000\n",
    "n_test = n_train/10 \n",
    "\n",
    "# Splitting to train and val set\n",
    "X = X_train[-n_train:]\n",
    "y = y_train[-n_train:]\n",
    "\n",
    "X_val = X_train[:n_test]\n",
    "y_val = y_train[:n_test]\n",
    "\n",
    "# Grid for hyper parameters to be tested\n",
    "cs = [0] \n",
    "degrees = [2, 3, 4]\n",
    "\n",
    "# Running part\n",
    "\n",
    "# Results storage\n",
    "scores = []\n",
    "y_preds = []\n",
    "for c in cs:\n",
    "    for degree in degrees:\n",
    "        print(degree)\n",
    "        svm = SVM(mode ='OVO', kernel='polynomial')\n",
    "        svm.fit(X, y)\n",
    "        y_pred = svm.predict(X_val)\n",
    "        y_preds.append(y_pred)\n",
    "        score = np.mean(y_pred == y_val)\n",
    "        scores.append(score)\n",
    "        print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.29999999999999999, 0.29999999999999999, 0.29999999999999999]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short test with n=2000, kernel = poly, mode = OVA\n",
    "* degree = 4 c = 1, accuracy 16%\n",
    "* degree = 3 c = 1, accuracy 20% \n",
    "* degree = 2 c = 1, accuracy 20%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "short test with n=4500 n_test = 500\n",
    "* degree = 2 c = 0 accuracy 32%!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
