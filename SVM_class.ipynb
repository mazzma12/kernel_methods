{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.95 s, sys: 116 ms, total: 5.06 s\n",
      "Wall time: 5.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_X_train = pd.read_csv('Xtr.csv', header=None, usecols=np.arange(3072))\n",
    "df_X_test = pd.read_csv('Xte.csv', header=None, usecols=np.arange(3072))\n",
    "df_y_train = pd.read_csv('Ytr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 ms, sys: 16 ms, total: 40 ms\n",
      "Wall time: 38.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = np.array(df_X_train, dtype=float)\n",
    "X_test = np.array(df_X_test, dtype=float)\n",
    "y_train = np.array(df_y_train['Prediction'], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from numpy import linalg\n",
    "import cvxopt\n",
    "from cvxopt import solvers, matrix\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2)\n",
    "\n",
    "def polynomial_kernel(x, y, p=3):\n",
    "    return (1 + np.dot(x, y)) ** p\n",
    "\n",
    "def gaussian_kernel(x, y, sigma=1):\n",
    "    return np.exp(-linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "\n",
    "def gaussian_kernel_matrix(X, sigma=0.5):\n",
    "    pairwise_dists = squareform(pdist(X, 'euclidean'))\n",
    "    K = scipy.exp(-sigma*pairwise_dists ** 2)\n",
    "    return K\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self, C=1, kernel='rbf', gamma=0.5):\n",
    "        self.C = C\n",
    "        self.kernel = kernel # kernel_function 'rbf', 'linear'\n",
    "        self.gamma = gamma # Kernel coefficient gamma for 'rbf'\n",
    "        \n",
    "    def fit(self, X, y, mode='OVA'):\n",
    "\n",
    "        self.n_sample_ = y.shape[0] # n_sample\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.alphas_ = {}\n",
    "        self.K_ = self.fit_kernel(X)\n",
    "        if mode == 'OVA':\n",
    "            for class_ in self.classes_:\n",
    "                y_copy = y.copy()\n",
    "                y_copy[y_copy != class_] = -1\n",
    "                y_copy[y_copy == class_] = 1\n",
    "                self.fit_dual(y_copy)\n",
    "                sol = solvers.qp(matrix(2*self.K_), matrix(self.p_), matrix(self.G_), matrix(self.h_))\n",
    "                self.alphas_[class_] = np.array(sol['x']).reshape(-1,)\n",
    "                \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        predictions = {}\n",
    "        self.K_test_ = self.fit_kernel(X_test)\n",
    "        self.n_test_ = X_test.shape[0] # size of the test sample\n",
    "        n = self.n_test_\n",
    "        res_mat = np.empty((self.classes_.shape[0], n))\n",
    "        \n",
    "        for class_ in self.classes_:\n",
    "            alpha = self.alphas_[class_]\n",
    "            res_mat[class_] = np.sum(alpha*self.K_test_, axis=1)\n",
    "        y_pred = res_mat.argmax(axis=0)\n",
    "        return y_pred  \n",
    "    \n",
    "    def fit_kernel(self, X):\n",
    "        \n",
    "        if self.kernel == 'rbf':\n",
    "            pairwise_dists = squareform(pdist(X, 'euclidean'))\n",
    "            K = scipy.exp(-self.gamma*pairwise_dists ** 2)\n",
    "            return K\n",
    "        \n",
    "        elif self.kernel == 'linear':\n",
    "            # In fact it's not a kernel\n",
    "            K = squareform(pdist(X, 'minkowski', 1))\n",
    "            return K\n",
    "        \n",
    "        else:\n",
    "            raise Exception('the kernel must either be rbf or linear')\n",
    "            \n",
    "    def fit_dual(self, y):\n",
    "        \n",
    "        n = self.n_sample_\n",
    "        diag_y = np.diag(y)\n",
    "        self.p_ = (-y).reshape(-1,1)\n",
    "        print(self.p_.shape)\n",
    "        self.Q_ = 2*self.K_ # Quadratic matrix\n",
    "        self.G_ = np.r_[diag_y, -diag_y] # Constraint matrix of size(2*n, n)\n",
    "        self.h_ = np.r_[self.C*np.ones(n), np.zeros(n)]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3072)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.3436e+01 -9.3239e+02  3e+03  2e+00  7e-16\n",
      " 1: -6.7455e+01 -5.5893e+02  6e+02  2e-01  5e-16\n",
      " 2: -7.2216e+01 -1.1183e+02  4e+01  3e-03  7e-16\n",
      " 3: -7.4473e+01 -7.7220e+01  3e+00  1e-04  3e-16\n",
      " 4: -7.4880e+01 -7.5107e+01  2e-01  8e-06  3e-16\n",
      " 5: -7.4944e+01 -7.4955e+01  1e-02  2e-07  2e-16\n",
      " 6: -7.4949e+01 -7.4950e+01  6e-04  2e-09  3e-16\n",
      " 7: -7.4950e+01 -7.4950e+01  3e-05  3e-11  2e-16\n",
      "Optimal solution found.\n",
      "(500, 1)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.2077e+01 -9.8460e+02  4e+03  2e+00  7e-16\n",
      " 1: -4.2382e+01 -6.0989e+02  8e+02  3e-01  6e-16\n",
      " 2: -4.4112e+01 -1.0233e+02  6e+01  2e-03  1e-15\n",
      " 3: -5.0692e+01 -5.4829e+01  4e+00  5e-05  5e-16\n",
      " 4: -5.1651e+01 -5.2034e+01  4e-01  3e-06  3e-16\n",
      " 5: -5.1827e+01 -5.1853e+01  3e-02  9e-08  2e-16\n",
      " 6: -5.1843e+01 -5.1844e+01  1e-03  1e-09  3e-16\n",
      " 7: -5.1844e+01 -5.1844e+01  5e-05  2e-11  3e-16\n",
      " 8: -5.1844e+01 -5.1844e+01  2e-06  2e-13  3e-16\n",
      "Optimal solution found.\n",
      "(500, 1)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.1956e+01 -9.3712e+02  4e+03  2e+00  7e-16\n",
      " 1: -6.5938e+01 -5.6337e+02  7e+02  2e-01  5e-16\n",
      " 2: -7.0814e+01 -1.1192e+02  4e+01  3e-03  8e-16\n",
      " 3: -7.3143e+01 -7.6463e+01  3e+00  2e-04  3e-16\n",
      " 4: -7.3574e+01 -7.3819e+01  2e-01  9e-06  3e-16\n",
      " 5: -7.3647e+01 -7.3661e+01  1e-02  2e-07  3e-16\n",
      " 6: -7.3653e+01 -7.3654e+01  7e-04  3e-09  3e-16\n",
      " 7: -7.3654e+01 -7.3654e+01  4e-05  4e-11  3e-16\n",
      "Optimal solution found.\n",
      "(500, 1)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.7092e+01 -9.4818e+02  4e+03  2e+00  7e-16\n",
      " 1: -6.0331e+01 -5.7545e+02  7e+02  2e-01  5e-16\n",
      " 2: -6.4947e+01 -1.1034e+02  5e+01  3e-03  6e-16\n",
      " 3: -6.8095e+01 -7.1765e+01  4e+00  2e-04  4e-16\n",
      " 4: -6.8648e+01 -6.8958e+01  3e-01  9e-06  3e-16\n",
      " 5: -6.8747e+01 -6.8767e+01  2e-02  2e-07  3e-16\n",
      " 6: -6.8756e+01 -6.8757e+01  1e-03  4e-09  3e-16\n",
      " 7: -6.8756e+01 -6.8757e+01  5e-05  5e-11  2e-16\n",
      "Optimal solution found.\n",
      "(500, 1)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.0801e+01 -9.4320e+02  4e+03  2e+00  6e-16\n",
      " 1: -6.4634e+01 -5.6945e+02  7e+02  2e-01  5e-16\n",
      " 2: -6.9415e+01 -1.1158e+02  4e+01  3e-03  1e-15\n",
      " 3: -7.1924e+01 -7.4901e+01  3e+00  2e-04  3e-16\n",
      " 4: -7.2373e+01 -7.2611e+01  2e-01  8e-06  2e-16\n",
      " 5: -7.2448e+01 -7.2462e+01  1e-02  2e-07  2e-16\n",
      " 6: -7.2454e+01 -7.2455e+01  8e-04  4e-09  2e-16\n",
      " 7: -7.2455e+01 -7.2455e+01  5e-05  5e-11  2e-16\n",
      "Optimal solution found.\n",
      "(500, 1)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.9744e+01 -9.4264e+02  4e+03  2e+00  7e-16\n",
      " 1: -6.3353e+01 -5.6929e+02  7e+02  2e-01  5e-16\n",
      " 2: -6.8131e+01 -1.1149e+02  4e+01  3e-03  6e-16\n",
      " 3: -7.0771e+01 -7.4151e+01  3e+00  2e-04  3e-16\n",
      " 4: -7.1250e+01 -7.1490e+01  2e-01  8e-06  3e-16\n",
      " 5: -7.1330e+01 -7.1343e+01  1e-02  2e-07  2e-16\n",
      " 6: -7.1336e+01 -7.1337e+01  6e-04  3e-09  3e-16\n",
      " 7: -7.1337e+01 -7.1337e+01  3e-05  3e-11  2e-16\n",
      "Optimal solution found.\n",
      "(500, 1)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.0277e+01 -9.5327e+02  4e+03  2e+00  7e-16\n",
      " 1: -5.2300e+01 -5.8165e+02  8e+02  2e-01  6e-16\n",
      " 2: -5.5879e+01 -1.0656e+02  5e+01  2e-03  3e-15\n",
      " 3: -6.0322e+01 -6.3966e+01  4e+00  1e-04  4e-16\n",
      " 4: -6.1039e+01 -6.1351e+01  3e-01  5e-06  2e-16\n",
      " 5: -6.1164e+01 -6.1184e+01  2e-02  1e-07  2e-16\n",
      " 6: -6.1175e+01 -6.1176e+01  1e-03  2e-09  2e-16\n",
      " 7: -6.1176e+01 -6.1176e+01  4e-05  2e-11  2e-16\n",
      "Optimal solution found.\n",
      "(500, 1)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.4888e+01 -9.7184e+02  4e+03  2e+00  7e-16\n",
      " 1: -4.5842e+01 -5.9872e+02  8e+02  2e-01  6e-16\n",
      " 2: -4.8264e+01 -1.0402e+02  6e+01  2e-03  3e-15\n",
      " 3: -5.4092e+01 -5.8101e+01  4e+00  7e-05  5e-16\n",
      " 4: -5.4967e+01 -5.5359e+01  4e-01  4e-06  3e-16\n",
      " 5: -5.5130e+01 -5.5158e+01  3e-02  1e-07  2e-16\n",
      " 6: -5.5146e+01 -5.5147e+01  1e-03  2e-09  2e-16\n",
      " 7: -5.5147e+01 -5.5147e+01  6e-05  3e-11  2e-16\n",
      " 8: -5.5147e+01 -5.5147e+01  2e-06  3e-13  3e-16\n",
      "Optimal solution found.\n",
      "(500, 1)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.4504e+01 -9.9853e+02  4e+03  2e+00  8e-16\n",
      " 1: -7.9383e+01 -6.1699e+02  7e+02  2e-01  5e-16\n",
      " 2: -8.4161e+01 -1.2261e+02  4e+01  3e-03  1e-15\n",
      " 3: -8.5627e+01 -8.8614e+01  3e+00  2e-04  3e-16\n",
      " 4: -8.5895e+01 -8.6069e+01  2e-01  8e-06  3e-16\n",
      " 5: -8.5939e+01 -8.5948e+01  9e-03  2e-07  3e-16\n",
      " 6: -8.5943e+01 -8.5944e+01  4e-04  2e-09  3e-16\n",
      " 7: -8.5944e+01 -8.5944e+01  1e-05  2e-11  3e-16\n",
      "Optimal solution found.\n",
      "(500, 1)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.4882e+01 -9.7942e+02  4e+03  2e+00  7e-16\n",
      " 1: -4.5693e+01 -6.0578e+02  8e+02  2e-01  6e-16\n",
      " 2: -4.7927e+01 -1.0494e+02  6e+01  2e-03  3e-15\n",
      " 3: -5.3893e+01 -5.8015e+01  4e+00  8e-05  5e-16\n",
      " 4: -5.4806e+01 -5.5211e+01  4e-01  5e-06  3e-16\n",
      " 5: -5.4978e+01 -5.5007e+01  3e-02  1e-07  3e-16\n",
      " 6: -5.4994e+01 -5.4996e+01  2e-03  2e-09  3e-16\n",
      " 7: -5.4995e+01 -5.4995e+01  8e-05  3e-11  3e-16\n",
      " 8: -5.4995e+01 -5.4995e+01  5e-06  3e-13  3e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.SVM at 0x7f89ec3ecf60>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train[:500]\n",
    "y = y_train[:500]\n",
    "svm = SVM()\n",
    "svm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:56: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "res = svm.predict(X_train[:500,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 ms, sys: 24 ms, total: 36 ms\n",
      "Wall time: 35.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = np.array(df_X_train)\n",
    "X_test = np.array(df_X_test)\n",
    "y_train = np.array(df_y_train['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computing_gram_matrix3(X, sigma=0.5):\n",
    "    f = lambda x, y: np.exp(-linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "    return squareform(pdist(X, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "def computing_gram_matrix(X, sigma=1):\n",
    "    n, p = X.shape\n",
    "    K = np.zeros((n,n))\n",
    "    for ii in range(n):\n",
    "        for kk in range(n):\n",
    "            K[ii, kk] = np.exp(-linalg.norm(X[ii]-X[kk])**2 / (2 * (sigma ** 2)))\n",
    "    return K\n",
    "\n",
    "def computing_gram_matrix2(X, sigma=1):\n",
    "    pairwise_dists = squareform(pdist(X, 'euclidean'))\n",
    "    K = scipy.exp(-pairwise_dists ** 2 / (2*sigma**2))\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 22s, sys: 64 ms, total: 10min 22s\n",
      "Wall time: 10min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "K1 = computing_gram_matrix(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.9 s, sys: 80 ms, total: 55 s\n",
      "Wall time: 55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "K2=computing_gram_matrix2(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.00866644,  0.02227502, ...,  0.0104907 ,\n",
       "         0.02156173,  0.01812238],\n",
       "       [ 0.00866644,  1.        ,  0.00345238, ...,  0.00275313,\n",
       "         0.00322442,  0.00347302],\n",
       "       [ 0.02227502,  0.00345238,  1.        , ...,  0.00580637,\n",
       "         0.0075947 ,  0.01033267],\n",
       "       ..., \n",
       "       [ 0.0104907 ,  0.00275313,  0.00580637, ...,  1.        ,\n",
       "         0.0033863 ,  0.00503564],\n",
       "       [ 0.02156173,  0.00322442,  0.0075947 , ...,  0.0033863 ,\n",
       "         1.        ,  0.00542766],\n",
       "       [ 0.01812238,  0.00347302,  0.01033267, ...,  0.00503564,\n",
       "         0.00542766,  1.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def __init__(self, penalty='l2', loss='squared_hinge', dual=True, tol=1e-4,\n",
    "                 C=1.0, multi_class='ovr', fit_intercept=True,\n",
    "                 intercept_scaling=1, class_weight=None, verbose=0,\n",
    "                 random_state=None, max_iter=1000):\n",
    "    self.dual = dual\n",
    "    self.tol = tol\n",
    "    self.C = C\n",
    "    self.multi_class = multi_class\n",
    "    self.fit_intercept = fit_intercept\n",
    "    self.intercept_scaling = intercept_scaling\n",
    "    self.class_weight = class_weight\n",
    "    self.verbose = verbose\n",
    "    self.random_state = random_state\n",
    "    self.max_iter = max_iter\n",
    "    self.penalty = penalty\n",
    "    self.loss = loss\n",
    "\n",
    "def fit(self, X, y, sample_weight=None):\n",
    "    \"\"\"Fit the model according to the given training data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "        Training vector, where n_samples in the number of samples and\n",
    "        n_features is the number of features.\n",
    "    y : array-like, shape = [n_samples]\n",
    "        Target vector relative to X\n",
    "    sample_weight : array-like, shape = [n_samples], optional\n",
    "        Array of weights that are assigned to individual\n",
    "        samples. If not provided,\n",
    "        then each sample is given unit weight.\n",
    "    Returns\n",
    "    -------\n",
    "    self : object\n",
    "        Returns self.\n",
    "    \"\"\"\n",
    "    # FIXME Remove l1/l2 support in 1.0 -----------------------------------\n",
    "    msg = (\"loss='%s' has been deprecated in favor of \"\n",
    "           \"loss='%s' as of 0.16. Backward compatibility\"\n",
    "           \" for the loss='%s' will be removed in %s\")\n",
    "\n",
    "    if self.loss in ('l1', 'l2'):\n",
    "        old_loss = self.loss\n",
    "        self.loss = {'l1': 'hinge', 'l2': 'squared_hinge'}.get(self.loss)\n",
    "        warnings.warn(msg % (old_loss, self.loss, old_loss, '1.0'),\n",
    "                      DeprecationWarning)\n",
    "    # ---------------------------------------------------------------------\n",
    "\n",
    "    if self.C < 0:\n",
    "        raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n",
    "                         % self.C)\n",
    "\n",
    "    X, y = check_X_y(X, y, accept_sparse='csr',\n",
    "                     dtype=np.float64, order=\"C\")\n",
    "    check_classification_targets(y)\n",
    "    self.classes_ = np.unique(y)\n",
    "\n",
    "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
    "        X, y, self.C, self.fit_intercept, self.intercept_scaling,\n",
    "        self.class_weight, self.penalty, self.dual, self.verbose,\n",
    "        self.max_iter, self.tol, self.random_state, self.multi_class,\n",
    "        self.loss, sample_weight=sample_weight)\n",
    "\n",
    "    if self.multi_class == \"crammer_singer\" and len(self.classes_) == 2:\n",
    "        self.coef_ = (self.coef_[1] - self.coef_[0]).reshape(1, -1)\n",
    "        if self.fit_intercept:\n",
    "            intercept = self.intercept_[1] - self.intercept_[0]\n",
    "            self.intercept_ = np.array([intercept])\n",
    "\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8a1f5e6ed48b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
